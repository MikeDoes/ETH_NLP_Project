{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "T5_Naive.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f324e30c68434a09840f1c90d44bb75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_213c0860bf01462684f175d1da1b629f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_979455066396427f89dac80ad176074e",
              "IPY_MODEL_d9f305149a7b4f5aa8ac41dac7f4227d",
              "IPY_MODEL_2f8bcb01bfb443dba3d277b1fc4162af"
            ]
          }
        },
        "213c0860bf01462684f175d1da1b629f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "979455066396427f89dac80ad176074e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a0ba0e9816a41e0a0af02f40eec179b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62387fa2215c48458abafffe0fa1526d"
          }
        },
        "d9f305149a7b4f5aa8ac41dac7f4227d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_496fd38b6f084daa833368bd3106598e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b6a2c542a514e6aaf24b25cd5ee2087"
          }
        },
        "2f8bcb01bfb443dba3d277b1fc4162af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_72280888699b4476896fe6b55fff063e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:00&lt;00:00, 1.17MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6dc38d7d8ea74ad88a237417a5ad0ef7"
          }
        },
        "4a0ba0e9816a41e0a0af02f40eec179b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62387fa2215c48458abafffe0fa1526d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "496fd38b6f084daa833368bd3106598e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b6a2c542a514e6aaf24b25cd5ee2087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72280888699b4476896fe6b55fff063e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6dc38d7d8ea74ad88a237417a5ad0ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da657036217d4e6aa6647cd119e85af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3c8b8ff50513462eb2b677222c3bf0eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8454be42fc1c4e319c79c53dc0c1a25e",
              "IPY_MODEL_6591db27dc8d4b28b30c6fa6dba122b3",
              "IPY_MODEL_85ea0d9c635842d5975f258686e65fca"
            ]
          }
        },
        "3c8b8ff50513462eb2b677222c3bf0eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8454be42fc1c4e319c79c53dc0c1a25e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f370123d19b84e7faa069494121b4f7f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3f473472e36481dae33abd6439a61a6"
          }
        },
        "6591db27dc8d4b28b30c6fa6dba122b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2defa64eecc746e8a6c13388a3f58a4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1389353,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1389353,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c7aa35b2f1d4e48ad2feb3a19395a43"
          }
        },
        "85ea0d9c635842d5975f258686e65fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8737df6163904aaeb8a5df1be623c3bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 1.45MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd3d1bf086464c77b34c700ef940f60a"
          }
        },
        "f370123d19b84e7faa069494121b4f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3f473472e36481dae33abd6439a61a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2defa64eecc746e8a6c13388a3f58a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c7aa35b2f1d4e48ad2feb3a19395a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8737df6163904aaeb8a5df1be623c3bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd3d1bf086464c77b34c700ef940f60a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b65231fbd18e42d89c2565a1ca0f3e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6ad4f041f2a4e6f854f64e518e48861",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_044046424f1345698ac74ddd1b8e1c36",
              "IPY_MODEL_e1c0d37bccfe499a92c313b30e61fc3c",
              "IPY_MODEL_44eaae4d232b401db9349ffe890e56b6"
            ]
          }
        },
        "d6ad4f041f2a4e6f854f64e518e48861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "044046424f1345698ac74ddd1b8e1c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c3dceed6a6a54c43b0c353be4122e0c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3ac25365f7746048edab889c6ab1441"
          }
        },
        "e1c0d37bccfe499a92c313b30e61fc3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_761983d75ac1431d9ae2e0958b0f6b13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1197,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1197,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad4b035fbba64b5cacb86e70f978e0a8"
          }
        },
        "44eaae4d232b401db9349ffe890e56b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf2a606fc83a4aa983da62eab8c6f020",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:00&lt;00:00, 27.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83ea93f6bd72401a87fa834ebc3e2bef"
          }
        },
        "c3dceed6a6a54c43b0c353be4122e0c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3ac25365f7746048edab889c6ab1441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "761983d75ac1431d9ae2e0958b0f6b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad4b035fbba64b5cacb86e70f978e0a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf2a606fc83a4aa983da62eab8c6f020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83ea93f6bd72401a87fa834ebc3e2bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26be3f5f99344331ad3ca2f3486a5651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f30702ba32e14b338147ce964f08635d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8800403865c047b9896358397c036000",
              "IPY_MODEL_e937519e4a7247e28fd1d21fc84f057f",
              "IPY_MODEL_8bcd70cd4dcc45f6a92766a77e497ad3"
            ]
          }
        },
        "f30702ba32e14b338147ce964f08635d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8800403865c047b9896358397c036000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6800e75124be4df6b298b89eccdde404",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c31786c4c2c9412692b2e45934b4f131"
          }
        },
        "e937519e4a7247e28fd1d21fc84f057f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a20e082ec2a64bf6b5c9b37849efe072",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 242065649,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 242065649,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a5981bb61dd4a87a9a396460896f8f7"
          }
        },
        "8bcd70cd4dcc45f6a92766a77e497ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_32118b7a59a842bdb412c0c6deabbb95",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 242M/242M [00:08&lt;00:00, 30.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b17225650bbd482c82c31eaddbde9b01"
          }
        },
        "6800e75124be4df6b298b89eccdde404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c31786c4c2c9412692b2e45934b4f131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a20e082ec2a64bf6b5c9b37849efe072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a5981bb61dd4a87a9a396460896f8f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32118b7a59a842bdb412c0c6deabbb95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b17225650bbd482c82c31eaddbde9b01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBS0rIyembad",
        "outputId": "d8222935-0356-4621-a06f-353edf5839ad"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install tokenizers\n",
        "!pip install transformers\n",
        "\n",
        "import torch.nn as nn\n",
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import T5ForConditionalGeneration , T5Tokenizer  , AdamW\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset , DataLoader"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.10.3\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 49.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.16 pyyaml-5.4.1 sacremoses-0.0.45 transformers-4.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlLX-k-omnDK",
        "outputId": "029441da-6bb4-48f0-cc98-472123e90110"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #this part has to be commented out if used on cluster\n",
        "!nvidia-smi\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Wed Sep  8 11:47:27 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P8    35W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJkLTjM_6mNn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "f324e30c68434a09840f1c90d44bb75e",
            "213c0860bf01462684f175d1da1b629f",
            "979455066396427f89dac80ad176074e",
            "d9f305149a7b4f5aa8ac41dac7f4227d",
            "2f8bcb01bfb443dba3d277b1fc4162af",
            "4a0ba0e9816a41e0a0af02f40eec179b",
            "62387fa2215c48458abafffe0fa1526d",
            "496fd38b6f084daa833368bd3106598e",
            "2b6a2c542a514e6aaf24b25cd5ee2087",
            "72280888699b4476896fe6b55fff063e",
            "6dc38d7d8ea74ad88a237417a5ad0ef7",
            "da657036217d4e6aa6647cd119e85af3",
            "3c8b8ff50513462eb2b677222c3bf0eb",
            "8454be42fc1c4e319c79c53dc0c1a25e",
            "6591db27dc8d4b28b30c6fa6dba122b3",
            "85ea0d9c635842d5975f258686e65fca",
            "f370123d19b84e7faa069494121b4f7f",
            "f3f473472e36481dae33abd6439a61a6",
            "2defa64eecc746e8a6c13388a3f58a4b",
            "5c7aa35b2f1d4e48ad2feb3a19395a43",
            "8737df6163904aaeb8a5df1be623c3bb",
            "dd3d1bf086464c77b34c700ef940f60a",
            "b65231fbd18e42d89c2565a1ca0f3e22",
            "d6ad4f041f2a4e6f854f64e518e48861",
            "044046424f1345698ac74ddd1b8e1c36",
            "e1c0d37bccfe499a92c313b30e61fc3c",
            "44eaae4d232b401db9349ffe890e56b6",
            "c3dceed6a6a54c43b0c353be4122e0c9",
            "e3ac25365f7746048edab889c6ab1441",
            "761983d75ac1431d9ae2e0958b0f6b13",
            "ad4b035fbba64b5cacb86e70f978e0a8",
            "bf2a606fc83a4aa983da62eab8c6f020",
            "83ea93f6bd72401a87fa834ebc3e2bef"
          ]
        },
        "id": "ExeavrU09Cvs",
        "outputId": "e1742aea-da0e-4bc9-8d00-952a55494374"
      },
      "source": [
        "N_EPOCHS=25\n",
        "accumulation_steps=5\n",
        "NUM_EPOCHS=N_EPOCHS\n",
        "BATCH_SIZE=8\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "MODEL_NAME=\"t5-small\"\n",
        "tokenizer=T5Tokenizer.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f324e30c68434a09840f1c90d44bb75e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da657036217d4e6aa6647cd119e85af3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b65231fbd18e42d89c2565a1ca0f3e22",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojJE0kTsoan9",
        "outputId": "55f3381a-1d78-4e51-e545-4e27bd1a2127"
      },
      "source": [
        "with Path(\"/content/drive/MyDrive/reranker.json\").open() as json_file: #this path has to be adjusted to local if used on the cluster\n",
        "  data=json.load(json_file)\n",
        "  \n",
        "data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Answer': 'physician assistants are medical providers who are licensed to diagnose and treat illness and disease and to prescribe medication for patients',\n",
              " 'Passage': 'The Physician Assistant Board or their representative may require proof or demonstration of competence from any physician assistant for any medical services performed. If a physician assistant determines a task, procedure or diagnostic problem exceeds his or her level of competence, then the physician assistant shall either consult with a physician or refer such cases to a physician. Click here to review a sample Delegation of Services Agreement. Question: What if a physician assistant works for more than one supervising physician at a hospital or clinic? Do we need to have separate DSAs for each supervising physician? Answer: The Board has had questions regarding how the DSA would be written if a physician assistant works for more than one supervising physician at a hospital or clinic. If the duties and medical services performed are consistent with each supervising physician, then one DSA can be written to include several supervising physicians. Each supervising physician must sign and date the DSA, along with the signature of the physician assistant. Question: What if a physician assistant works for one supervising physician who is an ob-gyn, and also works for an ortho supervising physician, and both are at the same clinic or hospital? Answer: If the duties and medical services provided by the physician assistant differ from one supervising physician to another, then it is recommended that a separate DSA be written for each supervising physician. However, one DSA could be used, but it would need to be separated with which duties are allowed under each supervising physician. Again, signatures and dates from all parties must be included on the DSA.',\n",
              " 'Query': \"What is a physician's assistant?\",\n",
              " 'Score': '',\n",
              " 'id': '1_1'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "ucFy4Q8VodTN",
        "outputId": "ab2d9b0b-685f-4968-8d65-92adf6218ddb"
      },
      "source": [
        "def extract_qa( path_1 : Path):\n",
        "  with path_1.open() as json_file:\n",
        "    data=json.load(json_file)\n",
        "  data_rows=[]\n",
        "  for element in data:\n",
        "    question=element[\"Query\"]\n",
        "    passage=element[\"Passage\"]\n",
        "    answer=element[\"Answer\"]\n",
        "    ID=element[\"id\"]\n",
        "\n",
        "    data_rows.append({\n",
        "        \"question\":question,\n",
        "        \"passage\":passage,\n",
        "        \"answer\":answer,\n",
        "        \"model_answer\":'',\n",
        "        \"id\":ID\n",
        "\n",
        "    })\n",
        "\n",
        "  return pd.DataFrame(data_rows)\n",
        "      \n",
        "\n",
        "train_df=extract_qa(Path(\"/content/drive/MyDrive/reranker.json\"))\n",
        "\n",
        "element=train_df.iloc[0]\n",
        "element[\"question\"]+\" \"+element['passage']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"What is a physician's assistant? The Physician Assistant Board or their representative may require proof or demonstration of competence from any physician assistant for any medical services performed. If a physician assistant determines a task, procedure or diagnostic problem exceeds his or her level of competence, then the physician assistant shall either consult with a physician or refer such cases to a physician. Click here to review a sample Delegation of Services Agreement. Question: What if a physician assistant works for more than one supervising physician at a hospital or clinic? Do we need to have separate DSAs for each supervising physician? Answer: The Board has had questions regarding how the DSA would be written if a physician assistant works for more than one supervising physician at a hospital or clinic. If the duties and medical services performed are consistent with each supervising physician, then one DSA can be written to include several supervising physicians. Each supervising physician must sign and date the DSA, along with the signature of the physician assistant. Question: What if a physician assistant works for one supervising physician who is an ob-gyn, and also works for an ortho supervising physician, and both are at the same clinic or hospital? Answer: If the duties and medical services provided by the physician assistant differ from one supervising physician to another, then it is recommended that a separate DSA be written for each supervising physician. However, one DSA could be used, but it would need to be separated with which duties are allowed under each supervising physician. Again, signatures and dates from all parties must be included on the DSA.\""
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqfn4t0fQiHH"
      },
      "source": [
        "class QADataset(Dataset):\n",
        "  def __init__(\n",
        "      self,\n",
        "      data: pd.DataFrame,\n",
        "      tokenizer: T5Tokenizer,\n",
        "      source_max_token_len: int=396,\n",
        "      target_max_token_len: int=32,\n",
        "  ):\n",
        "\n",
        "      self.tokenizer=tokenizer,\n",
        "      self.data=data\n",
        "      self.source_max_token_len=source_max_token_len\n",
        "      self.target_max_token_len=target_max_token_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,index:int):\n",
        "\n",
        "    ##DATA ROW\n",
        "    data_row=self.data.iloc[index]\n",
        "\n",
        "\n",
        "    ##SOURCE ENCODING\n",
        "    source_encoding=tokenizer(\n",
        "    data_row[\"question\"],\n",
        "    data_row[\"passage\"],\n",
        "    max_length=self.source_max_token_len,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True, \n",
        "    return_attention_mask=True,\n",
        "    add_special_tokens=True,\n",
        "    return_tensors=\"pt\" )\n",
        "\n",
        "    ##TARGET ENCODING\n",
        "    target_encoding=tokenizer(\n",
        "    data_row[\"answer\"],\n",
        "    max_length=self.target_max_token_len,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True, \n",
        "    return_attention_mask=True,\n",
        "    add_special_tokens=True,\n",
        "    return_tensors=\"pt\" )\n",
        "\n",
        "    labels=target_encoding[\"input_ids\"]\n",
        "    labels[labels==0]=-100\n",
        "\n",
        "\n",
        "    return dict(\n",
        "        # question=data_row[\"question\"],\n",
        "        # passage=data_row[\"passage\"],\n",
        "        # answer=data_row[\"answer\"],\n",
        "        input_ids=source_encoding[\"input_ids\"],\n",
        "        attention_mask=source_encoding[\"attention_mask\"],\n",
        "        labels=labels,\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZkIAoM1RjPM"
      },
      "source": [
        "class QAmodel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME , return_dict=True).to(device)\n",
        "    \n",
        "\n",
        "  def forward(self , input_ids , attention_mask , labels ):\n",
        "\n",
        "    output=self.model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      labels=labels\n",
        "    )   \n",
        "\n",
        "    \n",
        "    return output\n",
        "\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return AdamW(self.parameters(),lr=0.0001)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vztTrzox7v9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d18af4-7ba8-4fe9-ff31-ce66ac78b30f"
      },
      "source": [
        "\n",
        "dataset=QADataset(train_df,tokenizer,)\n",
        "print(dataset.__len__())\n",
        "data_module = DataLoader(dataset, batch_size=BATCH_SIZE,shuffle=\"True\")\n",
        "for batch in data_module:\n",
        "    print(torch.squeeze(batch[\"labels\"]).shape)\n",
        "    print(batch[\"input_ids\"].shape)\n",
        "    print(batch[\"attention_mask\"].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 32])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([8, 1, 396])\n",
            "torch.Size([4, 32])\n",
            "torch.Size([4, 1, 396])\n",
            "torch.Size([4, 1, 396])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc3OWYOEpApp"
      },
      "source": [
        "def model_training(data_module):\n",
        "  T5=QAmodel()\n",
        "\n",
        "\n",
        "  T5=T5.to(device)\n",
        "  optimizer=T5.configure_optimizers()\n",
        "\n",
        "  training_loss=[]\n",
        "  _validation_loss=[]\n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  for i in range (NUM_EPOCHS):\n",
        "    print(f\"epoch--{i}\")\n",
        "    loss_count=0\n",
        "    k=0\n",
        "    T5.train()\n",
        "    for batch in data_module:\n",
        "\n",
        "      input_ids=torch.squeeze(batch[\"input_ids\"])\n",
        "      attention_mask=torch.squeeze(batch[\"attention_mask\"])\n",
        "      labels=torch.squeeze(batch[\"labels\"])\n",
        "\n",
        "      \n",
        "      input_ids=input_ids.to(device)\n",
        "      attention_mask=attention_mask.to(device)\n",
        "      labels=labels.to(device)\n",
        "      \n",
        "\n",
        "      output=T5.forward(input_ids,attention_mask,labels)\n",
        "      loss=output.loss/accumulation_steps\n",
        "      loss.backward()\n",
        "      k+=1\n",
        "\n",
        "      # print(f\"label shape --:{labels.shape}\")\n",
        "      # print(f\"output shape --:{output.keys()}\")\n",
        "\n",
        "      if(k % accumulation_steps == 0):\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        loss_count+=loss.item()*accumulation_steps\n",
        "\n",
        "\n",
        "        if(k % 50 ==0):\n",
        "          mean_loss=loss_count/50\n",
        "          print(f\"average loss --:{mean_loss}\")\n",
        "          training_loss.append(mean_loss)\n",
        "          loss_count=0\n",
        "\n",
        "  return T5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "26be3f5f99344331ad3ca2f3486a5651",
            "f30702ba32e14b338147ce964f08635d",
            "8800403865c047b9896358397c036000",
            "e937519e4a7247e28fd1d21fc84f057f",
            "8bcd70cd4dcc45f6a92766a77e497ad3",
            "6800e75124be4df6b298b89eccdde404",
            "c31786c4c2c9412692b2e45934b4f131",
            "a20e082ec2a64bf6b5c9b37849efe072",
            "1a5981bb61dd4a87a9a396460896f8f7",
            "32118b7a59a842bdb412c0c6deabbb95",
            "b17225650bbd482c82c31eaddbde9b01"
          ]
        },
        "id": "nkE61QO636Kk",
        "outputId": "c2d369ee-6e38-4ec1-f105-923e687efdde"
      },
      "source": [
        "model=model_training(data_module)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26be3f5f99344331ad3ca2f3486a5651",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch--0\n",
            "average loss --:4.086854290962219\n",
            "average loss --:3.849925547838211\n",
            "average loss --:3.7359195411205293\n",
            "average loss --:3.614553213119507\n",
            "average loss --:3.5392633855342863\n",
            "epoch--1\n",
            "average loss --:3.4070584774017334\n",
            "average loss --:3.4188349425792692\n",
            "average loss --:3.304509735107422\n",
            "average loss --:3.175950226187706\n",
            "average loss --:3.1777968287467955\n",
            "epoch--2\n",
            "average loss --:3.056026482582092\n",
            "average loss --:3.0732685208320616\n",
            "average loss --:3.0503828167915343\n",
            "average loss --:2.905544212460518\n",
            "average loss --:2.912466874718666\n",
            "epoch--3\n",
            "average loss --:2.73279447555542\n",
            "average loss --:2.8111242324113848\n",
            "average loss --:2.7372071534395217\n",
            "average loss --:2.6629266113042833\n",
            "average loss --:2.657633674144745\n",
            "epoch--4\n",
            "average loss --:2.5187560260295867\n",
            "average loss --:2.537011590600014\n",
            "average loss --:2.4127118676900863\n",
            "average loss --:2.3618388026952744\n",
            "average loss --:2.4287737756967545\n",
            "epoch--5\n",
            "average loss --:2.272772526741028\n",
            "average loss --:2.2624068766832353\n",
            "average loss --:2.2052439361810685\n",
            "average loss --:2.2021823942661287\n",
            "average loss --:2.1769482761621477\n",
            "epoch--6\n",
            "average loss --:2.057010480761528\n",
            "average loss --:2.0343749642372133\n",
            "average loss --:1.9966817945241928\n",
            "average loss --:1.9911130249500275\n",
            "average loss --:1.9461855202913285\n",
            "epoch--7\n",
            "average loss --:1.9033164083957672\n",
            "average loss --:1.8542222052812576\n",
            "average loss --:1.8146388918161391\n",
            "average loss --:1.7454127699136734\n",
            "average loss --:1.6970988243818284\n",
            "epoch--8\n",
            "average loss --:1.7153542250394822\n",
            "average loss --:1.6854781329631805\n",
            "average loss --:1.6009129196405412\n",
            "average loss --:1.6001026034355164\n",
            "average loss --:1.5125789955258369\n",
            "epoch--9\n",
            "average loss --:1.5466863319277764\n",
            "average loss --:1.4813975051045418\n",
            "average loss --:1.4627004727721213\n",
            "average loss --:1.405631737411022\n",
            "average loss --:1.3964097261428834\n",
            "epoch--10\n",
            "average loss --:1.3422528073191642\n",
            "average loss --:1.3484897449612618\n",
            "average loss --:1.3034023210406303\n",
            "average loss --:1.2563410714268683\n",
            "average loss --:1.2833220794796945\n",
            "epoch--11\n",
            "average loss --:1.2385158196091652\n",
            "average loss --:1.1673097029328345\n",
            "average loss --:1.1634707599878311\n",
            "average loss --:1.129559488594532\n",
            "average loss --:1.1337539121508597\n",
            "epoch--12\n",
            "average loss --:1.0687566906213761\n",
            "average loss --:1.055470246076584\n",
            "average loss --:1.0319593638181686\n",
            "average loss --:1.0323114961385726\n",
            "average loss --:0.9812979832291603\n",
            "epoch--13\n",
            "average loss --:0.9547745019197464\n",
            "average loss --:0.9585316970944404\n",
            "average loss --:0.9515127792954445\n",
            "average loss --:0.8937767647206784\n",
            "average loss --:0.8937141716480255\n",
            "epoch--14\n",
            "average loss --:0.8527861401438713\n",
            "average loss --:0.8930809646844864\n",
            "average loss --:0.8203911758959294\n",
            "average loss --:0.802522100508213\n",
            "average loss --:0.7979576796293258\n",
            "epoch--15\n",
            "average loss --:0.7919134221971035\n",
            "average loss --:0.7516347654163837\n",
            "average loss --:0.739705390483141\n",
            "average loss --:0.7057442888617516\n",
            "average loss --:0.7207006774842739\n",
            "epoch--16\n",
            "average loss --:0.7186942212283611\n",
            "average loss --:0.6728043749928474\n",
            "average loss --:0.6700566001236439\n",
            "average loss --:0.6295617304742336\n",
            "average loss --:0.6516936503350734\n",
            "epoch--17\n",
            "average loss --:0.6383754916489124\n",
            "average loss --:0.5862066496163607\n",
            "average loss --:0.6002156518399715\n",
            "average loss --:0.6031486988067627\n",
            "average loss --:0.5747825399041175\n",
            "epoch--18\n",
            "average loss --:0.5183838844299317\n",
            "average loss --:0.5563305906951428\n",
            "average loss --:0.542717969417572\n",
            "average loss --:0.5301250893622637\n",
            "average loss --:0.5131254181265831\n",
            "epoch--19\n",
            "average loss --:0.504966738820076\n",
            "average loss --:0.478034458309412\n",
            "average loss --:0.49076366052031517\n",
            "average loss --:0.4731776021420956\n",
            "average loss --:0.470365883782506\n",
            "epoch--20\n",
            "average loss --:0.44574002996087075\n",
            "average loss --:0.43081331737339496\n",
            "average loss --:0.4384088672697544\n",
            "average loss --:0.425052397698164\n",
            "average loss --:0.41676844023168086\n",
            "epoch--21\n",
            "average loss --:0.3963024191558361\n",
            "average loss --:0.40324773266911507\n",
            "average loss --:0.3914847504347563\n",
            "average loss --:0.37431684099137785\n",
            "average loss --:0.37426452785730363\n",
            "epoch--22\n",
            "average loss --:0.35814075395464895\n",
            "average loss --:0.34630971401929855\n",
            "average loss --:0.35903271809220316\n",
            "average loss --:0.3483735453337431\n",
            "average loss --:0.342840189114213\n",
            "epoch--23\n",
            "average loss --:0.32872832342982294\n",
            "average loss --:0.3326756343245506\n",
            "average loss --:0.30735532343387606\n",
            "average loss --:0.3205049343407154\n",
            "average loss --:0.31977703906595706\n",
            "epoch--24\n",
            "average loss --:0.30985179282724856\n",
            "average loss --:0.29480862878263\n",
            "average loss --:0.285881869867444\n",
            "average loss --:0.28722545206546785\n",
            "average loss --:0.276480276696384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLv324HsMLdV"
      },
      "source": [
        "torch.save(model.state_dict(), Path('/content/drive/MyDrive/model.pt'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YcBIz040FXT"
      },
      "source": [
        "def generate_answer(data_row,model):\n",
        "  source_encoding=tokenizer(\n",
        "    data_row[\"question\"],\n",
        "    data_row[\"passage\"],\n",
        "    max_length=80,\n",
        "    padding=\"max_length\",\n",
        "    truncation=\"only_second\", \n",
        "    return_attention_mask=True,\n",
        "    add_special_tokens=True,\n",
        "    return_tensors=\"pt\" )\n",
        "  source_encoding=source_encoding.to(device)\n",
        "\n",
        "  generated_ids = model.model.generate(\n",
        "      input_ids=source_encoding[\"input_ids\"],\n",
        "      attention_mask=source_encoding[\"attention_mask\"],\n",
        "      num_beams=1,\n",
        "      max_length=80,\n",
        "      repetition_penalty=2.5,\n",
        "      length_penalty=1.0,\n",
        "      early_stopping=True,\n",
        "      use_cache=True\n",
        "  )\n",
        "\n",
        "  preds=[\n",
        "         tokenizer.decode(generated_id , skip_special_tokens=True , clean_up_tokenization_spaces=True)\n",
        "         for generated_id in generated_ids\n",
        "  ]\n",
        "\n",
        "  return \"\".join(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Ph8MZo6n9-",
        "outputId": "849a1268-b287-4698-db01-3f9cba9a871f"
      },
      "source": [
        "sample=train_df.iloc[18]\n",
        "sample[\"question\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"What are the educational requirements required to become a physician's assistant?\""
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ojPS1me7rFb",
        "outputId": "a55a3a54-0df6-44ad-9f72-7f42443ffca9"
      },
      "source": [
        "sample[\"answer\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Complete your bachelor's degree (a science or healthcare related major is usually best); Gain experience either working or volunteering in a healthcare setting; Apply to ARC-PA accredited physician assistant programs; Complete a 2-3 year, master's level PA program;\""
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo6HXZ2z7uF0",
        "outputId": "7a8d61a9-6453-4246-85e2-fba7ae81160e"
      },
      "source": [
        "print(generate_answer(sample,model))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete your bachelor's degree (a science or occupational education) and become a licensed physician. You may apply to the state of New York State Department of Health\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_by9vCPsn7Wv"
      },
      "source": [
        "for i in train_df.index:\n",
        "  train_df.at[i,\"model_answer\"]=generate_answer(train_df.iloc[i],model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0WyvZqXZdNK"
      },
      "source": [
        "train_df.to_json(Path('/content/drive/MyDrive/train_df.json'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvr9XhyrVhb9"
      },
      "source": [
        "def question_extractor( query_path : Path ):\n",
        "  with query_path.open() as json_file:\n",
        "    questions=json.load(json_file)\n",
        "\n",
        "\n",
        "  question_rows=[]\n",
        "  for Q in questions:\n",
        "    question=Q[\"Rewrite\"]\n",
        "    answer=Q[\"Answer\"]\n",
        "    id=str(Q['Conversation_no'])+\"_\"+str(Q['Turn_no'])\n",
        "\n",
        "\n",
        "\n",
        "    question_rows.append({\n",
        "        \"question\":question,\n",
        "        \"answer\":answer,\n",
        "        \"passage\":'', #not really a passage , will be used to stack previous answers\n",
        "        \"id\":id\n",
        "\n",
        "    })\n",
        "\n",
        "  return pd.DataFrame(question_rows)\n",
        "      \n",
        "def question_collector(question_df,train_df):\n",
        "  #dataframes of questions and passages. passages also\n",
        "  #contain the answers generated by the model. collects all the answer corresponding\n",
        "  #to a certain id and stucks them into question_df \"passage\" key. Which will be \n",
        "  #used for model training\n",
        "  for i in question_df.index:\n",
        "    matching_answers=train_df.loc[train_df['id']==question_df.at[i,'id']]\n",
        "    for item in matching_answers['model_answer']:\n",
        "      question_df.at[i,\"passage\"]=str(question_df.at[i,\"passage\"]) +\" . \"+ str(item) #assembles the answers when they match the question\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU7Vo7470ywx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f2414d7-8499-48e2-f59f-82262836280c"
      },
      "source": [
        "question_df=question_extractor(Path(\"/content/drive/MyDrive/qrecc_test.json\"))\n",
        "question_collector(question_df,train_df)\n",
        "print(question_df.at[0,'answer'])\n",
        "print(question_df.at[0,'passage'])\n",
        "question_reduced=question_df.iloc[0:200]\n",
        "question_reduced.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "physician assistants are medical providers who are licensed to diagnose and treat illness and disease and to prescribe medication for patients\n",
            " . physician assistants are medical providers who may be assisting with diagnosing problems or illness, and should also consult the patient for consultation. . physician assistants are medical providers who are licensed to diagnose and treat illness, as well as other health professionals who may be involved in consultation or counseling. Physician . Licensed Nurses Assistant (AP) – An assistant who can be trained to diagnose and treat illness, disease or stroke. . Physician Assistants provide clinical research and treatment for patients who may be employed by the healthcare industry or local government. Physician assistants are licensed to diagnose, treat disease . physician assistants are medical providers who may prescribe medications for their patients, while physician associate programs generally have a better reputation as clinicians. Physician . physician assistants are medical providers who assist in the field of surgical procedure, and they provide medical care for those with diabetes. . Physician Assistants are medical professionals who are licensed to diagnose and treat illness and disease or disease. Physician . physician assistants are medical providers who are licensed to diagnose and treat illness, as well . A physician assistant is an assistant to the medical field, such as acupuncture, skin care (as well as facial . . physician assistants are medical providers who are licensed to diagnose and treat illness as well as treat psychotic patients\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>passage</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is a physician's assistant?</td>\n",
              "      <td>physician assistants are medical providers who...</td>\n",
              "      <td>. physician assistants are medical providers ...</td>\n",
              "      <td>1_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are the educational requirements required...</td>\n",
              "      <td>Complete your bachelor's degree (a science or ...</td>\n",
              "      <td>. Complete your bachelor's degree (a science ...</td>\n",
              "      <td>1_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What does it cost to become a physician's assi...</td>\n",
              "      <td>Average Cost Across all PA Schools for the 201...</td>\n",
              "      <td>. Average Cost Across all PA Schools for the ...</td>\n",
              "      <td>1_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What's the average starting salary for a physi...</td>\n",
              "      <td>Typical starting salaries for physician associ...</td>\n",
              "      <td>. Typical starting salaries for physician ass...</td>\n",
              "      <td>1_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What's the average starting salary for a physi...</td>\n",
              "      <td>An early career Physician Assistant (PA) with ...</td>\n",
              "      <td>. An early career Physician Assistant (PA) wi...</td>\n",
              "      <td>1_5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  ...   id\n",
              "0                   What is a physician's assistant?  ...  1_1\n",
              "1  What are the educational requirements required...  ...  1_2\n",
              "2  What does it cost to become a physician's assi...  ...  1_3\n",
              "3  What's the average starting salary for a physi...  ...  1_4\n",
              "4  What's the average starting salary for a physi...  ...  1_5\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCTxkQnnR6s9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2992cdf-aec6-4e45-c2bb-2e16dccc4dd8"
      },
      "source": [
        "print(len(question_df))\n",
        "print(len(train_df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16451\n",
            "2020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQGMXMkWmgO4"
      },
      "source": [
        "data_module2=QADataset(question_df,tokenizer,)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O0ytiiu1ruP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "100b9da2-c6c5-4517-9e9a-1d48d18dfc06"
      },
      "source": [
        "model_training(data_module2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch--0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-c75b01ca5062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_module2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-c49e17111fc7>\u001b[0m in \u001b[0;36mmodel_training\u001b[0;34m(data_module)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0maccumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-c00fb42733de>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     )   \n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1566\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m             )\n\u001b[1;32m   1570\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseModelOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;31m# required mask seq length can be calculated via length of past\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    }
  ]
}